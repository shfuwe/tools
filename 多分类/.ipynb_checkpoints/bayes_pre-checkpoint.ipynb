{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['新能源汽车', 0.9867690160541083, ['ICT:0.002260762034060226', '新能源汽车:0.9867690160541083', '生物医药:0.000969709968777577', '医疗器械:0.00036090812561861805', '钢铁:8.068983700896634e-05', '能源:0.00827086053231211', '工业机器人:0.000389800014411476', '先进轨道交通:1.3028017159287019e-05', '数控机床:0.00016944309633607987', '工业软件:0.0002301898648119734', '高端装备:3.660549376338843e-05', '半导体:6.920364388501734e-06', '人工智能:2.739467241641826e-05', '稀土:0.00041467192482425264']], ['新能源汽车', 0.9867690160541083, ['ICT:0.002260762034060226', '新能源汽车:0.9867690160541083', '生物医药:0.000969709968777577', '医疗器械:0.00036090812561861805', '钢铁:8.068983700896634e-05', '能源:0.00827086053231211', '工业机器人:0.000389800014411476', '先进轨道交通:1.3028017159287019e-05', '数控机床:0.00016944309633607987', '工业软件:0.0002301898648119734', '高端装备:3.660549376338843e-05', '半导体:6.920364388501734e-06', '人工智能:2.739467241641826e-05', '稀土:0.00041467192482425264']]]\n",
      "['新能源汽车', '新能源汽车']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 分词\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    带有语料清洗功能的分词函数\n",
    "    \"\"\"\n",
    "    text = re.sub(\"\\{%.+?%\\}\", \" \", text)  # 去除 {%xxx%} (地理定位, 微博话题等)\n",
    "    text = re.sub(\"@.+?( |$)\", \" \", text)  # 去除 @xxx (用户名)\n",
    "    text = re.sub(\"【.+?】\", \" \", text)  # 去除 【xx】 (里面的内容通常都不是用户自己写的)\n",
    "    icons = re.findall(\"\\[.+?\\]\", text)  # 提取出所有表情图标\n",
    "    text = re.sub(\"\\[.+?\\]\", \"IconMark\", text)  # 将文本中的图标替换为`IconMark`\n",
    "\n",
    "    tokens = []\n",
    "    for k, w in enumerate(jieba.lcut(text)):\n",
    "        w = w.strip()\n",
    "        if \"IconMark\" in w:  # 将IconMark替换为原图标\n",
    "            for i in range(w.count(\"IconMark\")):\n",
    "                tokens.append(icons.pop(0))\n",
    "        elif w and w != '\\u200b' and w.isalpha():  # 只保留有效文本\n",
    "            tokens.append(w)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "pp = './data'\n",
    "# 加载模型\n",
    "model_path0 = pp+'/bayes_01.02.pkl'\n",
    "model0 = joblib.load(model_path0)\n",
    "# 加载词典\n",
    "vec_path0 = pp+'/feature_01.02.pkl'\n",
    "vec0 = CountVectorizer(decode_error=\"replace\", vocabulary=pickle.load(open(vec_path0, \"rb\")))\n",
    "\n",
    "\n",
    "# 处理数据\n",
    "def getType(string_l):\n",
    "    type_=['ICT', '新能源汽车', '生物医药', '医疗器械', '钢铁', \n",
    "       '能源', '工业机器人', '先进轨道交通', '数控机床',  '工业软件', \n",
    "       '高端装备', '半导体', '人工智能', '稀土']\n",
    "    \n",
    "    if isinstance(string_l,str):\n",
    "        string_l=[string_l]\n",
    "    if isinstance(string_l,list):\n",
    "        X_data = []\n",
    "        for string in string_l:\n",
    "            X_data.append(\" \".join(tokenize(string)))\n",
    "\n",
    "        vecc = vec0.transform(X_data)\n",
    "        result_pre = model0.predict(vecc)\n",
    "        result_pre_proba = model0.predict_proba(vecc)\n",
    "        \n",
    "        res=[]\n",
    "        for i in range(len(string_l)):\n",
    "            sin_res=[]\n",
    "            end_index=result_pre[i]\n",
    "            end_score=result_pre_proba[i][end_index]\n",
    "            if end_score<0.75:\n",
    "                sin_res.append('其他')\n",
    "                sin_res.append(-1)\n",
    "            else:\n",
    "                sin_res.append(type_[end_index])\n",
    "                sin_res.append(end_score)\n",
    "            sin_res.append([type_[j]+':'+str(result_pre_proba[i][j]) for j in range(len(type_))])\n",
    "            res.append(sin_res)\n",
    "        return res\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    string = [\"2018沃德十佳发动机公布，国内可以买到哪些车型？\",\"2018沃德十佳发动机公布，国内可以买到哪些车型？\"]\n",
    "    result=getType(string)\n",
    "    print(result)\n",
    "    all_res=[i[0] for i in result]\n",
    "    print(all_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw0",
   "language": "python",
   "name": "sw0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
